import os
import math
import torch
import numpy as np
import pickle
import argparse
import torchvision.utils as vutils
from diffusion_utils.utils import add_parent_path
import torchvision
import imageio
import matplotlib.pyplot as plt
from matplotlib import gridspec

from eval_conf import eval_cfg

# Data
add_parent_path(level=1)
from datasets.data import get_data, get_data_id, add_data_args, get_plot_transform

# Model
from model import get_model, get_model_id, add_model_args
from diffusion_utils.base import DataParallelDistribution

from scipy.interpolate import griddata

import cv2 

###########
## Setup ##
###########

parser = argparse.ArgumentParser()
parser.add_argument('--model', type=str, default=None)
parser.add_argument('--samples', type=int, default=64)
parser.add_argument('--nrow', type=int, default=8)
parser.add_argument('--seed', type=int, default=0)
parser.add_argument('--double', type=eval, default=False)
eval_args = parser.parse_args()

path_args = '{}/args.pickle'.format(eval_args.model)
path_check = '{}/check/checkpoint.pt'.format(eval_args.model)

torch.manual_seed(eval_args.seed)

###############
## Load args ##
###############

with open(path_args, 'rb') as f:
    args = pickle.load(f)

##################
## Specify data ##
##################

# train_loader is not used in this file; args is loaded from the save trained args
train_loader, eval_loader, data_shape, num_classes = get_data(args)

###################
## Specify model ##
###################

model = get_model(args, data_shape=data_shape)
if args.parallel == 'dp':
    model = DataParallelDistribution(model)

if torch.cuda.is_available():
    checkpoint = torch.load(path_check)
else:
    checkpoint = torch.load(path_check, map_location='cpu')
model.load_state_dict(checkpoint['model'])

if torch.cuda.is_available():
    model = model.cuda()

print('Loaded weights for model at {}/{} epochs'.format(checkpoint['current_epoch'], args.epochs))

# ========================== New Code ==========================\
print('In inpaint_sample, args.dataset: ', args.dataset)

plot_transform = get_plot_transform(args)

# Load testing data
for minibatch_data in eval_loader:
    model_kwargs = {}
    
    input = minibatch_data['input']
    gt = minibatch_data['gt']
    gt_mask = minibatch_data['gt_mask']

    # # ==================== ACDC data ====================   
    # data_root = '/home/zheng/Softwares/Experiments/diff/testing_data/cityscapes'
    # npy_path = os.path.join(data_root, 'GP020606_frame_000470_rgb_anon.npy')
    # mask_path = os.path.join(data_root, 'mask.npy')
    
    # resolution = (256, 128)
    # seg_logit = np.load(npy_path)
    # seg_id = np.argmax(seg_logit, axis=0)
    # print(seg_id)
    # seg_id = cv2.resize(seg_id, resolution, interpolation=cv2.INTER_NEAREST)
    # mask = np.load(mask_path)
    # mask = cv2.resize(mask, resolution, interpolation=cv2.INTER_NEAREST)
    
    # input = torch.tensor(seg_id).unsqueeze(0).unsqueeze(0).long()
    # gt = input
    # gt_mask = torch.tensor(mask).unsqueeze(0).unsqueeze(0).long()
    # # ==================== ACDC data ====================
    
    model_kwargs['input'] = input
    model_kwargs['gt'] = gt
    model_kwargs['gt_mask'] = gt_mask
    
    input_id_np = input[0][0].detach().cpu().numpy()
    
    # shape: (1, h, w)
    gt_mask_np = gt_mask[0][0].detach().cpu().numpy()
    
    img_h = input_id_np.shape[0]
    img_w = input_id_np.shape[1]
    grid_x, grid_y = np.mgrid[0:1:complex(False, img_h), 0:1:complex(False, img_w)]
    
    valid_pos = np.where(gt_mask_np==1.)
    values = input_id_np[gt_mask_np==1.]    
    
    # Covert the coordinates of points to be within [0, 1]    
    points = np.hstack((valid_pos[0][:, np.newaxis].astype(float)/img_h, valid_pos[1][:, np.newaxis].astype(float)/img_w))

    # nan values can be generated by methods OTHER THAN 'nearest'
    grid = griddata(points, values, (grid_x, grid_y), method='nearest')
    
    # Get the position of nan values
    nan_pos = np.argwhere(np.isnan(grid))
    
    if len(nan_pos): # if there are nans
        # print('nan pos: ', nan_pos)
        grid[nan_pos[:, 0], nan_pos[:, 1]] = 0 # assign 1 (Road) to nan-valued positions; 0 is the 255 label
    else: # if there is no nan
        print('No nan there...')
        
    # Make sure the label is int
    grid = grid.astype(int)
    
    grid_tensor = torch.from_numpy(grid)
    grid_tensor = grid_tensor.unsqueeze(0)
    grid_tensor = grid_tensor.unsqueeze(0)
    
    sample_fn = model.p_sample_loop_inpa
    
    result = sample_fn(
        model_kwargs=model_kwargs,
        eval_cfg=eval_cfg
    )
    
    # The input to plot_transform must be torch tensor on cpu    
    result = result.cpu()
    gt = gt.cpu()
    input = input.cpu()
    
    print('input shape: ', input.shape)
    print('result shape: ', result.shape)
    print('gt shape: ', gt.shape)
    
    input_color = plot_transform(input).to(torch.uint8)
    grid_tensor_color = plot_transform(grid_tensor).to(torch.uint8)
    result[result==15] = 1
    colored_result = plot_transform(result).to(torch.uint8)
    gt_color = plot_transform(gt).to(torch.uint8)
    
    # shape: (3, h, w)
    input_color_np = input_color[0].detach().cpu().numpy()
    grid_color_np = grid_tensor_color[0].detach().cpu().numpy()
    colored_result_np = colored_result[0].detach().cpu().numpy()
    gt_color_np = gt_color[0].detach().cpu().numpy()
    
    input_color_np = np.transpose(input_color_np, (1,2,0))
    grid_color_np = np.transpose(grid_color_np, (1,2,0))
    colored_result_np = np.transpose(colored_result_np, (1,2,0))
    gt_color_np = np.transpose(gt_color_np, (1,2,0))
    
    fig = plt.figure(figsize=(14, 7))
    nrow = 1
    ncol = 5
    
    gs = gridspec.GridSpec(nrow, ncol,
                        wspace=0.0, hspace=-0.56, 
                        top=1.-0.5/(nrow+1), bottom=0.5/(nrow+1), 
                        left=0.5/(ncol+1), right=1-0.5/(ncol+1))

    ax1 = fig.add_subplot(gs[0,0])
    im1 = ax1.imshow(input_color_np)
    ax1.set_yticklabels([])
    ax1.set_xticklabels([])
    if args.dataset == 'nuscenes':
        ax1.invert_yaxis()
    ax1.axis('off')
    
    ax2 = fig.add_subplot(gs[0,1])
    im2 = ax2.imshow(gt_mask_np)
    ax2.set_yticklabels([])
    ax2.set_xticklabels([])
    if args.dataset == 'nuscenes':
        ax2.invert_yaxis()
    ax2.axis('off')
    
    ax3 = fig.add_subplot(gs[0,2])
    im3 = ax3.imshow(grid_color_np)
    ax3.set_yticklabels([])
    ax3.set_xticklabels([])
    if args.dataset == 'nuscenes':
        ax3.invert_yaxis()
    ax3.axis('off')
    
    ax4 = fig.add_subplot(gs[0,3])
    im4 = ax4.imshow(colored_result_np)
    ax4.set_yticklabels([])
    ax4.set_xticklabels([])
    if args.dataset == 'nuscenes':
        ax4.invert_yaxis()
    ax4.axis('off')
    
    ax5 = fig.add_subplot(gs[0,4])
    im5 = ax5.imshow(gt_color_np)
    ax5.set_yticklabels([])
    ax5.set_xticklabels([])
    if args.dataset == 'nuscenes':
        ax5.invert_yaxis()
    ax5.axis('off')
    
    plt.show()   